version: "3.8"

services:
  # -------------------------
  # Hadoop (HDFS + YARN)
  # -------------------------
  namenode:
#    image: bde2020/hadoop-namenode:2.0.0-hadoop3.2.1-java8
    image: packet23/hadoop-hdfs-namenode:3-java-11
    container_name: namenode
    hostname: namenode
    ports:
      - "9870:9870"   # NameNode UI
      - "8020:8020"   # HDFS
    volumes:
      - ./conf/hadoop:/etc/hadoop:ro
      - namenode:/hadoop/dfs/name
    environment:
      - HADOOP_CONF_DIR=/etc/hadoop
      - YARN_CONF_DIR=/etc/hadoop
      - CLUSTER_NAME=lakehouse
    env_file:
      - ./hadoop.env

  datanode:
    #image: bde2020/hadoop-datanode:2.0.0-hadoop3.2.1-java8
    image: packet23/hadoop-hdfs-datanode:3-java-11
    container_name: datanode
    hostname: datanode
    depends_on:
      - namenode
    ports:
      - "9864:9864"   # DataNode UI
    volumes:
      - ./conf/hadoop:/etc/hadoop:ro
      - datanode:/hadoop/dfs/data
    environment:
      - HADOOP_CONF_DIR=/etc/hadoop
      - YARN_CONF_DIR=/etc/hadoop
      - SERVICE_PRECONDITION=namenode:9870 namenode:8020
    env_file:
      - ./hadoop.env

  resourcemanager:
    #image: bde2020/hadoop-resourcemanager:2.0.0-hadoop3.2.1-java8
    image: packet23/hadoop-yarn-resourcemanager:3-java-11
    container_name: resourcemanager
    hostname: resourcemanager
    depends_on:
      - namenode
      - datanode
    ports:
      - "8088:8088"   # YARN RM UI
    environment:
      - HADOOP_CONF_DIR=/etc/hadoop
      - YARN_CONF_DIR=/etc/hadoop
      - SERVICE_PRECONDITION=namenode:9870 namenode:8020 datanode:9864
    env_file:
      - ./hadoop.env
    volumes:
      - ./conf/hadoop:/etc/hadoop:ro

  nodemanager:
 #   image: bde2020/hadoop-nodemanager:2.0.0-hadoop3.2.1-java8
    image: packet23/hadoop-yarn-nodemanager:3.3-java-11
    container_name: nodemanager
    hostname: nodemanager
    depends_on:
      - resourcemanager
    ports:
      - "8042:8042"   # NodeManager UI
    environment:
      - HADOOP_CONF_DIR=/etc/hadoop
      - YARN_CONF_DIR=/etc/hadoop
      - SERVICE_PRECONDITION=namenode:9870 namenode:8020 datanode:9864 resourcemanager:8088
    env_file:
      - ./hadoop.env
    volumes:
      - ./conf/hadoop:/etc/hadoop:ro

  historyserver:
    #image: bde2020/hadoop-historyserver:2.0.0-hadoop3.2.1-java8
    image: packet23/hadoop-mapred-jobhistoryserver:3-java-11
    container_name: historyserver
    hostname: historyserver
    depends_on:
      - namenode
      - datanode
      - resourcemanager
    ports:
      - "8188:8188"   # YARN History UI
    volumes:
      - ./conf/hadoop:/etc/hadoop:ro
      - historyserver:/hadoop/yarn/timeline
    environment:
      - HADOOP_CONF_DIR=/etc/hadoop
      - YARN_CONF_DIR=/etc/hadoop
      - SERVICE_PRECONDITION=namenode:9870 namenode:8020 datanode:9864 resourcemanager:8088
    env_file:
      - ./hadoop.env

  # -------------------------
  # S3 (MinIO)
  # -------------------------
  minio:
    image: quay.io/minio/minio:latest
    container_name: minio
    ports:
      - "19000:9000"   # S3 API
      - "19001:9001"   # Console
    environment:
      - MINIO_ROOT_USER=admin
      - MINIO_ROOT_PASSWORD=password
      - MINIO_REGION=us-east-1
    command: server /data --console-address ":9001"
    volumes:
      - minio:/data

  minio-mc:
    image: quay.io/minio/mc:latest
    container_name: minio-mc
    depends_on:
      - minio
    entrypoint: >
      /bin/sh -c "
      until mc alias set myminio http://minio:9000 admin password; do sleep 2; done;
      mc mb -p myminio/warehouse || true;
      exit 0;
      "

  # -------------------------
  # Nessie (Iceberg REST catalog)
  # -------------------------
  nessie:
    image: ghcr.io/projectnessie/nessie:0.106.0
    container_name: nessie
    depends_on:
      - minio-mc
    ports:
      - "19120:19120"
    environment:
      - nessie.version.store.type=IN_MEMORY
      - nessie.server.authentication.enabled=false

      # Default warehouse points at MinIO bucket
      - nessie.catalog.default-warehouse=warehouse
      - nessie.catalog.warehouses.warehouse.location=s3://warehouse/

      # S3/MinIO settings (server-side)
      - nessie.catalog.service.s3.default-options.endpoint=http://minio:9000/
      - nessie.catalog.service.s3.default-options.path-style-access=true
      - nessie.catalog.service.s3.default-options.auth-type=STATIC
      - nessie.catalog.service.s3.default-options.region=us-east-1

      # Secrets wiring (Quarkus secret reference)
      - nessie.catalog.service.s3.default-options.access-key=urn:nessie-secret:quarkus:nessie.catalog.secrets.access-key
      - nessie.catalog.secrets.access-key.name=admin
      - nessie.catalog.secrets.access-key.secret=password

  # -------------------------
  # Spark client (runs against YARN)
  # -------------------------
  spark:
    image: spark:3.5.1
    container_name: spark
    depends_on:
      - resourcemanager
      - nessie
    command: ["bash", "-lc", "sleep infinity"]
    environment:
      - HADOOP_CONF_DIR=/etc/hadoop
      - YARN_CONF_DIR=/etc/hadoop

      # Optional: if you *also* want direct S3A access from Spark side
      - AWS_REGION=us-east-1
      - AWS_ACCESS_KEY_ID=admin
      - AWS_SECRET_ACCESS_KEY=password
    volumes:
      - spark-ivy:/tmp/ivy
      - ./conf/hadoop:/etc/hadoop:ro
      - ./conf/spark:/opt/spark/conf:ro


  trino-coordinator:
    image: trinodb/trino:476
    container_name: trino-coordinator
    networks: [mnet]
    ports:
      - "8080:8080"
    volumes:
      - ./trino/coordinator/config.properties:/etc/trino/config.properties
      - ./trino/catalog/iceberg.properties:/etc/trino/catalog/iceberg.properties
      - ./trino/coordinator/init.sql:/etc/trino/init.sql
    depends_on:
      - mc

  trino-worker-1:
    image: trinodb/trino:476
    container_name: trino-worker-1
    networks: [mnet]
    volumes:
      - ./trino/worker/config.properties:/etc/trino/config.properties
      - ./trino/catalog/iceberg.properties:/etc/trino/catalog/iceberg.properties
    depends_on:
      - trino-coordinator

  trino-worker-2:
    image: trinodb/trino:476
    container_name: trino-worker-2
    networks: [mnet]
    volumes:
      - ./trino/worker/config.properties:/etc/trino/config.properties
      - ./trino/catalog/iceberg.properties:/etc/trino/catalog/iceberg.properties
    depends_on:
      - trino-coordinator

#   jupyter:
#     image: jupyter/pyspark-notebook:latest
#     ports: ["8888:8888"]
#     networks: [mnet]
#     depends_on:
#       - catalog
#       - storage
#     environment:
#       AWS_ACCESS_KEY_ID: admin
#       AWS_SECRET_ACCESS_KEY: password
#       AWS_REGION: us-east-1
#       AWS_EC2_METADATA_DISABLED: "true"
#       SPARK_SUBMIT_OPTS: "-Divy.cache.dir=/tmp -Divy.home=/tmp"
#       #         --packages org.apache.iceberg:iceberg-spark-runtime-3.5_2.12:1.5.2,software.amazon.awssdk:bundle:2.20.131,software.amazon.awssdk:url-connection-client:2.20.131,org.projectnessie.nessie-integrations:nessie-spark-extensions-3.5_2.12:0.106.0
#
#     volumes:
#       - ./spark/spark-defaults1.conf:/usr/local/spark/conf/spark-defaults.conf:ro

volumes:
  namenode:
  datanode:
  historyserver:
  minio:
  spark-ivy:
