  spark-master:
    image: apache/spark:3.5.0
    container_name: spark-master
    command: bash -c "/opt/spark/sbin/start-master.sh && tail -f /dev/null"
    environment:
      - SPARK_MODE=master
      - SPARK_MASTER_HOST=0.0.0.0
      - SPARK_MASTER_PORT=7077
      - SPARK_MASTER_WEBUI_PORT=8080
      # creds for the AWS SDK inside the driver (if you run spark-submit here)
      - AWS_ACCESS_KEY_ID=admin
      - AWS_SECRET_ACCESS_KEY=password
      - AWS_REGION=us-east-1
      - AWS_EC2_METADATA_DISABLED=true
    volumes:
      - ./spark/spark-defaults.conf:/opt/spark/conf/spark-defaults.conf:ro

    ports:
      - "8090:8080"
      - "7077:7077"
    networks: [mnet]

  spark-worker-1:
    image: apache/spark:3.5.0
    container_name: spark-worker-1
    command: bash -c "/opt/spark/sbin/start-worker.sh spark://spark-master:7077 && tail -f /dev/null"
    environment:
      - SPARK_MODE=worker
      - AWS_ACCESS_KEY_ID=admin
      - AWS_SECRET_ACCESS_KEY=password
      - AWS_REGION=us-east-1
      - AWS_EC2_METADATA_DISABLED=true
    volumes:
      - ./spark/spark-defaults.conf:/opt/spark/conf/spark-defaults.conf:ro
    networks: [mnet]
    depends_on: [spark-master]

  spark-worker-2:
    image: apache/spark:3.5.0
    container_name: spark-worker-2
    command: bash -c "/opt/spark/sbin/start-worker.sh spark://spark-master:7077 && tail -f /dev/null"
    environment:
      - SPARK_MODE=worker
      - AWS_ACCESS_KEY_ID=admin
      - AWS_SECRET_ACCESS_KEY=password
      - AWS_REGION=us-east-1
      - AWS_EC2_METADATA_DISABLED=true
    volumes:
      - ./spark/spark-defaults.conf:/opt/spark/conf/spark-defaults.conf:ro
    networks: [mnet]
    depends_on: [spark-master]